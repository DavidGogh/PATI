{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ropi_tangible_surface.common_imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "import cv2\n",
    "\n",
    "import rospy\n",
    "import tf\n",
    "import rospkg\n",
    "import message_filters\n",
    "from sensor_msgs.msg import Image, CameraInfo\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "from geometry_msgs.msg import Point\n",
    "\n",
    "from ropi_msgs.msg import *\n",
    "from ropi_msgs.srv import *\n",
    "\n",
    "from ropi_tangible_surface.transform import four_point_transform\n",
    "from ropi_tangible_surface.fingertip_detection import *\n",
    "from ropi_tangible_surface.fingertip_tracking import *\n",
    "from ropi_tangible_surface.object_detection import *\n",
    "from ropi_tangible_surface.object_tracking import *\n",
    "\n",
    "from ropi_tangible_surface.selection import *\n",
    "from pick_and_place import *\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_threshold = lambda img, l, u: (img < u) * (img > l) * img\n",
    "flip_array = lambda a: np.hstack((np.hsplit(a, 2)[1], np.hsplit(a, 2)[0]))\n",
    "tip_angle = lambda tip_pt, pt1, pt2: np.arctan2(pt2[1] - tip_pt[1], pt2[0] - tip_pt[0]) - np.arctan2(pt1[1] - tip_pt[1], pt1[0] - tip_pt[0])\n",
    "euclidean_dist = lambda pt1, pt2: np.linalg.norm(np.array(pt1) - np.array(pt2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TangibleSurface:\n",
    "    def __init__(self, resolution = (800, 450), use_skin_color_filter=True):\n",
    "        # Constants and params\n",
    "        self.resolution = resolution\n",
    "        # self.aspect_ratio = resolution[0] / resolution[1]\n",
    "        self.use_skin_color_filter = use_skin_color_filter\n",
    "        self.load_data()\n",
    "        self.on_init()\n",
    "\n",
    "    def load_data(self):\n",
    "        self.root_path = rospkg.RosPack().get_path('ropi_tangible_surface')\n",
    "        self.ref_pts = np.load(self.root_path + '/config/points.npy')\n",
    "        rospy.loginfo('Load reference points: ' + repr(np.asarray([self.ref_pts])))\n",
    "        self.depth_background = np.load(self.root_path + '/config/depth.npy')\n",
    "\n",
    "    def on_init(self):\n",
    "        rospy.loginfo(\"on init\")\n",
    "        # Instances\n",
    "        self.bridge = CvBridge()\n",
    "        self.touch_detections = [FingertipDetection()] * 2\n",
    "        self.touch_tracker_manager = TouchTrackerManager(self.resolution)\n",
    "\n",
    "        self.object_detector = ObjectManager()\n",
    "        self.object_tracker_manager = ObjectTrackerManager(self.resolution)\n",
    "        \n",
    "#         self.selection_manager = SelectionManager(self.resolution)\n",
    "\n",
    "        # publish amd subscribe\n",
    "        self.finger_pub = rospy.Publisher(\"touch\", MultiTouch, queue_size=50)\n",
    "        self.skin_pub = rospy.Publisher(\"skin\", Image, queue_size=50)\n",
    "        self.debug_pub = rospy.Publisher(\"debug\", Image, queue_size=50)\n",
    "        self.obj_pub = rospy.Publisher(\"obj\", Image, queue_size=50)\n",
    "        self.subscribe('/kinect2/sd/image_color_rect',\n",
    "                       '/kinect2/sd/image_depth_rect')\n",
    "\n",
    "    def subscribe(self, img_topic, depth_topic):\n",
    "        rospy.loginfo('subscribing')\n",
    "        depth_sub = message_filters.Subscriber(depth_topic, Image)\n",
    "        rgb_sub = message_filters.Subscriber(img_topic, Image)\n",
    "        self.ts = message_filters.TimeSynchronizer([depth_sub, rgb_sub], 20)\n",
    "        # self.ts = message_filters.ApproximateTimeSynchronizer(\n",
    "        #     [depth_sub, rgb_sub], 5, 0.0012)\n",
    "        self.ts.registerCallback(self.image_callback)\n",
    "#         self.region_selection_server = rospy.Service(\n",
    "#             'region_selection', RegionSelection, self.region_selection_callback)\n",
    "#         self.delete_selection_server = rospy.Service(\n",
    "#             'delete_selection', DeleteSelection, self.delete_selection_callback)\n",
    "#         self.move_server = rospy.Service(\n",
    "#             'move_objects', MoveObjects, self.move_objects_callback)\n",
    "#         self.is_moving = False\n",
    "#         self.grasp_pub = rospy.Publisher('grasp_data', GraspData, queue_size=1)\n",
    "\n",
    "    def ur5_init(self):\n",
    "        rospy.loginfo('init ur5')\n",
    "        self.robot_interface = PickNPlace()\n",
    "\n",
    "    def detect_objects_in_region(self, msg):\n",
    "        self.selection_manager.update([msg])\n",
    "        region = self.selection_manager.selections.get(msg.guid)\n",
    "        rect = region.normalized_rect\n",
    "        grasp_points = self.object_detector.get_grasp_selected(rect)\n",
    "        return grasp_points\n",
    "\n",
    "    def move_objects_callback(self, req):\n",
    "        # TODO: finish this\n",
    "        rospy.loginfo(\"move objects service called.\")\n",
    "        response = MoveObjectsResponse()\n",
    "        if not self.is_moving:\n",
    "            self.is_moving = True\n",
    "            mission = self.mission_from_regions(req.source_selection, req.target_selection)\n",
    "            # if there are objects in the region\n",
    "            if mission is not None:\n",
    "                response.success = True\n",
    "                response.message = '{} source objects detected.'.format(len(mission))\n",
    "                rospy.loginfo('mission generated, executing mission.')\n",
    "                # response.object_data = [x.make_msg() for x in mission]\n",
    "                # self.grasp_pub.publish([x.make_msg() for x in mission])\n",
    "                try:\n",
    "                    self.robot_interface.pick_and_place_mission(mission)\n",
    "                except:\n",
    "                    rospy.logerr('mission failed.')\n",
    "                    response.success = False\n",
    "                    response.message = 'mission failed'\n",
    "                    return response\n",
    "            else:\n",
    "                response.success = False\n",
    "                response.message = 'No source objects detected.'\n",
    "                return response\n",
    "            self.is_moving = False\n",
    "        else:\n",
    "            rospy.logwarn('moving, rejected')\n",
    "        response.success = True\n",
    "        response.message = 'Running, duplicated request.'\n",
    "        return response\n",
    "\n",
    "    def place_position(self, pick_pos, source, target):\n",
    "        relative_pos = np.asarray(pick_pos) - source.normalized_rect.get_center()\n",
    "        scale = target.normalized_rect.diameter / source.normalized_rect.diameter\n",
    "        if scale > 1:\n",
    "            relative_pos = relative_pos * scale\n",
    "        return target.normalized_rect.get_center() + relative_pos\n",
    "\n",
    "    def mission_from_regions(self, source_region, target_region):\n",
    "        print('Source: ', source_region)\n",
    "        print('Target: ', target_region)\n",
    "        grasp_points = self.detect_objects_in_region(source_region)\n",
    "        print('Obj: ', grasp_points)\n",
    "        if len(grasp_points) > 0:\n",
    "            self.selection_manager.update([target_region])\n",
    "            target = self.selection_manager.selections.get(target_region.guid)\n",
    "            source = self.selection_manager.selections.get(source_region.guid)\n",
    "            # print('centes: ', source.normalized_rect.get_center())\n",
    "            # print('centes: ', target.normalized_rect.get_center())\n",
    "            # movement = target.normalized_rect.get_center() - source.normalized_rect.get_center()\n",
    "            # print('Displacement: {}'.format(movement))\n",
    "            for g in grasp_points:\n",
    "                g.target_position = np.int0(self.place_position(g.position, source, target))\n",
    "            print('Mission: {}'.format(grasp_points))\n",
    "            return grasp_points\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def delete_selection_callback(self, req):\n",
    "        rospy.loginfo(\"Delete selection service called.\")\n",
    "        print (self.selection_manager.selections)\n",
    "        self.selection_manager.delete([req.guid])\n",
    "        print (self.selection_manager.selections)\n",
    "        response = DeleteSelectionResponse()\n",
    "        response.success = True\n",
    "        response.message = 'Selection deleted.'\n",
    "        return response\n",
    "\n",
    "    def region_selection_callback(self, req):\n",
    "        rospy.loginfo(\"Region selection service called.\")\n",
    "        grasp_points = self.detect_objects_in_region(req)\n",
    "\n",
    "        response = RegionSelectionResponse()\n",
    "        rospy.loginfo('Contructing response.')\n",
    "        response.success = (len(grasp_points) > 0)\n",
    "        response.message = repr(len(grasp_points)) + ' Obejcts found.'\n",
    "        if response.success:\n",
    "            grasp_data = []\n",
    "            for gp in grasp_points:\n",
    "                grasp_datum = GraspData()\n",
    "                grasp_datum.position.x = gp.position[0]\n",
    "                grasp_datum.position.y = gp.position[1]\n",
    "                grasp_datum.diameter = gp.diameter \n",
    "                grasp_datum.angle = gp.angle\n",
    "                grasp_datum.height = gp.height\n",
    "                grasp_data.append(grasp_datum)\n",
    "            response.grasp_data = grasp_data\n",
    "        return response\n",
    "\n",
    "    def image_callback(self, depth_in, rgb_in):\n",
    "        cv_rgb = self.rgb_callback(rgb_in)\n",
    "        cv_depth = self.depth_callback(depth_in)\n",
    "        depth_foreground = self.depth_background - cv_depth\n",
    "        # depth_foreground = self.filter(depth_foreground, size=3)\n",
    "        depth_foreground[depth_foreground < 5] = 0\n",
    "        # mask = my_threshold(depth_foreground, 50, 300))\n",
    "        if (self.use_skin_color_filter):\n",
    "            skin_mask = self.filter_skin(cv_rgb)\n",
    "            skin = cv2.bitwise_and(\n",
    "                depth_foreground, depth_foreground, mask=skin_mask)\n",
    "            objects = cv2.bitwise_and(\n",
    "                depth_foreground, depth_foreground, mask=~skin_mask)\n",
    "        else:\n",
    "            skin = depth_foreground.copy()\n",
    "            objects = depth_foreground.copy()\n",
    "        # warpped depth & rgb image for objects detection\n",
    "        object_rgb_warpped = four_point_transform(cv_rgb, self.ref_pts)\n",
    "        objects_warped = four_point_transform(objects, self.ref_pts)\n",
    "        self.debug_pub.publish(self.bridge.cv2_to_imgmsg(object_rgb_warpped))\n",
    "        # self.selection_manager.update_image(objects_warped, object_rgb_warpped)\n",
    "        objects = self.detect_object(objects_warped)\n",
    "        self.object_tracker_manager.update(objects)\n",
    "        # earpprd depth image for fingertip detection\n",
    "        depth_warped = four_point_transform(skin, self.ref_pts)\n",
    "        points = self.detect_fingertip(depth_warped)\n",
    "        self.touch_tracker_manager.update(points)\n",
    "\n",
    "        # print(self.touch_tracker_manager.make_msg())\n",
    "        self.finger_pub.publish(self.touch_tracker_manager.make_msg())\n",
    "\n",
    "\n",
    "    def rgb_callback(self, data):\n",
    "        try:\n",
    "            cv_image = copy.copy(self.bridge.imgmsg_to_cv2(data))\n",
    "            return cv_image\n",
    "        except CvBridgeError as e:\n",
    "            print(e)\n",
    "\n",
    "    def filter_skin(self, image):\n",
    "        converted = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        lower = np.array([0, 45, 60], dtype=\"uint8\")\n",
    "        upper = np.array([20, 150, 255], dtype=\"uint8\")\n",
    "        #lower = np.array([119, 59, 37], dtype = \"uint8\")\n",
    "        #upper = np.array([150, 255, 255], dtype = \"uint8\")\n",
    "        skin_mask = cv2.inRange(converted, lower, upper)\n",
    "        skin_mask = self.filter(skin_mask)\n",
    "        # skin = cv2.bitwise_and(cv_image, cv_image, mask=skin_mask)\n",
    "        # self.skin_pub.publish(self.bridge.cv2_to_imgmsg(skin_mask))\n",
    "        return skin_mask\n",
    "\n",
    "    def depth_callback(self, data):\n",
    "        try:\n",
    "            cv_image = self.bridge.imgmsg_to_cv2(data)\n",
    "            mask = self.make_mask(np.asarray([self.ref_pts]), cv_image.shape)\n",
    "            masked_image = copy.copy(cv_image)\n",
    "            masked_image[np.isnan(masked_image)] = 0\n",
    "            masked_image[~mask] = 0\n",
    "            return masked_image\n",
    "        except CvBridgeError as e:\n",
    "            print(e)\n",
    "\n",
    "    def filter(self, mask, size=3):\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (size, size))\n",
    "        mask = cv2.erode(mask, kernel, iterations=2)\n",
    "        mask = cv2.dilate(mask, kernel, iterations=2)\n",
    "        mask = cv2.GaussianBlur(mask, (3, 3), 0)\n",
    "        return mask\n",
    "\n",
    "    def find_contour(self, mask):\n",
    "        _, contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL,\n",
    "                                          cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "        return contours\n",
    "\n",
    "    def make_mask(self, pts, shape):\n",
    "        roi_corners = pts.astype(np.int32)\n",
    "        mask = np.zeros(shape, dtype=np.uint8)[:, :, np.newaxis]\n",
    "        cv2.fillPoly(mask, np.array([roi_corners]), (255, ))\n",
    "        mask = mask.astype(np.bool)\n",
    "        mask = np.resize(mask, shape)\n",
    "        return mask\n",
    "\n",
    "    def detect_fingertip(self, img):\n",
    "        threshed = my_threshold(img, 0, 500)\n",
    "        mask = np.zeros(img.shape, dtype=np.uint8)\n",
    "        mask[threshed > 0] = 255\n",
    "        dst = img.copy()\n",
    "        mask = self.filter(mask)\n",
    "        dst[~mask.astype(np.bool)] = 0\n",
    "        contours = self.find_contour(mask)\n",
    "        p = []\n",
    "        merge_list = lambda l1, l2: l2 if not l1 else (l1 if not l2 else np.concatenate((l1, l2)))\n",
    "        object_contours = []\n",
    "        hand_contours = []\n",
    "        if not self.is_moving or len(contours) != 0:\n",
    "            contours = filter(lambda c: cv2.contourArea(c) > 200, contours)\n",
    "            contours = np.asarray(sorted(\n",
    "                contours, key=lambda cnt: cv2.contourArea(cnt), reverse=True))\n",
    "            # filter out objects (hands' contour has nodes at edge)\n",
    "            hand_candidate_contours = list(\n",
    "                filter(lambda cnt: (True in [x[0][1] < 5 for x in cnt] or True in [x[0][0] < 5 for x in cnt]),\n",
    "                       contours))\n",
    "            hand_contours = np.asarray(hand_candidate_contours[0:2])\n",
    "            for cnt in contours:\n",
    "                if not np.any(hand_contours==cnt):\n",
    "                    object_contours.append(cnt)\n",
    "            debug_img = dst.copy()\n",
    "            debug_img = cv2.cvtColor(\n",
    "                debug_img.astype(np.uint8)[:, :, np.newaxis], cv2.COLOR_GRAY2BGR)\n",
    "            # cv2.drawContours(debug_img, hand_contours, -1, (0,255,0), 1)\n",
    "            # obj_debug_img = dst.copy()\n",
    "            for i, cnt in enumerate(hand_candidate_contours[0:2]):\n",
    "                p_new = self.touch_detections[i].update(cnt, dst, debug_img)\n",
    "                p = merge_list(p, p_new)\n",
    "                debug_img = self.touch_detections[i].debug_img\n",
    "            if len(p) != 0: \n",
    "                rospy.loginfo(repr(len(p)) + ' touch points: ' + repr(p))\n",
    "            self.skin_pub.publish(self.bridge.cv2_to_imgmsg(debug_img))\n",
    "        return p\n",
    "    \n",
    "    def detect_object(self, img):\n",
    "        objects = []\n",
    "        threshed = my_threshold(img, 5, 150)\n",
    "        mask = np.zeros(img.shape, dtype=np.uint8)\n",
    "        mask[threshed > 0] = 255\n",
    "        dst = img.copy()\n",
    "        mask = self.filter(mask)\n",
    "        dst[~mask.astype(np.bool)] = 0\n",
    "        contours = self.find_contour(mask)\n",
    "        merge_list = lambda l1, l2: l2 if not l1 else (l1 if not l2 else np.concatenate((l1, l2)))\n",
    "        object_contours = []\n",
    "        if len(contours) != 0:\n",
    "            # print([cv2.contourArea(c) for c in contours])\n",
    "            contours = filter(lambda c: cv2.contourArea(c) > 400 and cv2.contourArea(c) < 3000, contours)\n",
    "            debug_img = dst.copy()\n",
    "            objects = self.object_detector.update(contours, dst, debug_img)\n",
    "            debug_img = self.object_detector.debug_img\n",
    "            debug_img = self.selection_manager.draw(debug_img)\n",
    "            debug_img = self.object_detector.draw_selections(debug_img, self.selection_manager.get_rects())\n",
    "            self.obj_pub.publish(self.bridge.cv2_to_imgmsg(debug_img))\n",
    "        return objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    rospy.init_node(\"gest\")\n",
    "    dp = TangibleSurface(use_skin_color_filter=False)\n",
    "    try:\n",
    "        rospy.spin()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Shutting down\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [1538926358.142051]: Load reference points: array([[[ 89.,  58.],\n",
      "        [405.,  42.],\n",
      "        [409., 220.],\n",
      "        [102., 233.]]], dtype=float32)\n",
      "[INFO] [1538926358.143010]: on init\n"
     ]
    },
    {
     "ename": "ROSInterruptException",
     "evalue": "rospy shutdown",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------\u001b[0m",
      "\u001b[0;31mROSInterruptException\u001b[0m   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-6f82dc553b9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-b2170cea4173>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mrospy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gest\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTangibleSurface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_skin_color_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mrospy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-d07964f30318>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, resolution, use_skin_color_filter)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_skin_color_filter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_skin_color_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-d07964f30318>\u001b[0m in \u001b[0;36mon_init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbridge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCvBridge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtouch_detections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mFingertipDetection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtouch_tracker_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTouchTrackerManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_detector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mObjectManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/intuitive_computing/catkin_ws/src/RoPI/ropi_tangible_surface/scripts/ropi_tangible_surface/fingertip_tracking.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, screen_shape)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mTouchTrackerManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrackingManagerBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mrospy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_service\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'delete_cursor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_cursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrospy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mServiceProxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'delete_cursor'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeleteSelection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscreen_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/ros/kinetic/lib/python2.7/dist-packages/rospy/impl/tcpros_service.pyc\u001b[0m in \u001b[0;36mwait_for_service\u001b[0;34m(service, timeout)\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrospy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_shutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mROSInterruptException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rospy shutdown\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mROSInterruptException\u001b[0m: rospy shutdown"
     ]
    }
   ],
   "source": [
    "main(sys.argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
